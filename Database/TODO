###############################################################
	Some tasks depend on other tasks being done first.
	This is denoted by the
		x.y notation.
	Lower valued y's must be done before higher valued y's
	of the same x.
	
	Tasks with different x values may be done at any time
	independent of eachother.

	Tasks with equivalent x and y values may be done at 
	any time independent of eachother so long as the
	tasks with lower y values have been completed first.

	A task which has been complted should be moved to the
	bottom and the x.y value should be replaced by DONE.

	If you are working on a task, make sure to put your name
	next to the x.y value as in:
		Name x.y
	That way, others will know to work on something else
	or to consult you before working on the task that
	you have already been working on.
###############################################################

(1.1)
	ImportDatabase/importDatabaseFunction.php : importDatabase($database, $file) 
	-- Changes the data in the database to match the data in $file
	   $file is assumed to have the following format

	This is the format:
	"TableName"
	"Column1", "Column2",...
	"Data1","Data2",...
	"Data1","Data2",...

	"TableName2"
	...

	Here is the pseudocode for importDatabase($database, $file)
	  {    
		while(!file.eof()) //Can't remember off the top of my head
                {                  //what the actual way to check for EOF is
			tablename = readTableName();
			columns = readColumns();
			data = readData();
			updateDatabase(database, tablename,columns,data);
		}
	  }

	Here is the pseudocode for readTableName()

		{
		    tablename = readline;
		    removeQuotes(tableName); //Change "TableName" to TableName
		    return tableName;
		}
	
	Here is the pseudocode for readColumns();

		{
		    columns = readline;
		    columns = removeQuotes(columns);
		    columns = explode(columns,',');
		    return columns;
		}

	Here is the pseudocode for readData()

		{
		    //data will be an array, which will have arrays added to it.
		    //That is, data is a 2D array
		    data = Array();

		    line = readline;
		    while(line != "")
		    {
		    	row = replaceQuotesWithSingleQuotes(row);
		    	row = explode(row,',');
			data[] = row; //I think this works, maybe not
		    	row = readline;
		    }
		}
			
	Here is the pseudocode for updateDatabase(database, tablename,columns,data)

		{
		    for each element in data
		    {
			    query = generateUpdateQuery(tablename,columns,element);
			    mysqli_query(database,query);
		    }
		}

	Here is the pseudocode for generateUpdateQuery(tablename,columns,element)

		{
		    //Genereate the SET part of the query
		    set = ""
		    for index i in columns
		    {
			set = set . column[i] . "=" . element[i];
			if (i+1 < numberOfColumns)
			    set = set . ",";
		    }

		    return "UPDATE " . tablename . " SET" . set . " WHERE " . column[0] . "=" . element[0];
		}

---------------STUFF THAT'S DONE---------------------------
(DONE) Have convert.py output a file named TableNames
    which contains the name of a table with a corresponding
    .csv file for each file generated by the convert.py
    script. 

    The importDatabase.php script should then read in the
    names of the tables into the $tableNames array by
    parsing the TableNames file.
    
    This way, should convert.py change to create
    more (or less) or differently named tables, the 
    importDatabase.php script will not have to be edited
    in any way.

(DONE) Currently the importDatabase.php script must be ran from
    the command line. This is not very useful for programmers
    who simply want to import and invoke a function from their 
    own script. Most of importDatabase.php (the part that does
    not parse the command line) can be abstracted to a function
    accepting the interpreted command line arguments. The new
    file can be called importDatabaseFunctions.php. Then, the
    importDatabase.php script will simply call this function
    with the parsed command line.

(DONE)   Add a table to the database named Administrator
         Probably just give it generic stuff for right now

(DONE) We need to change convert.py to print out the names
	of the columns into the files containing the 
	table's data (i.e. Mentor.csv and Mentee.csv).

	Right now *.csv files have the format:
		row1
		row2
		row3

	All that needs to be changed is to print the column
	names at the top:
		column1 column2 column3
		row1
		row2
		row3

	**The rows contain data for each column**

	Then importDatabase() needs to add the data only to
	those columns.

	Which means 
	INSERT INTO table_name
	VALUES(value1, value2,..)
	
	becomes

	 INSERT INTO table_name (column1, column2, ...)
	 VALUES (value1, value2, ...)

	This will allow us to add columns to any part of the
	existing Mentor and Mentee tables without having
	to change the convert.py or importDatabase() scripts.

(DONE)   Add the following columns to the Mentee table (make them varchar(200)
	because alot of these are going to allow for multiple selections
	from a list, so they could get really long)
		Add column : "ExtendedDegree" to Mentee after "Major"
		PreferredName
		CUID
		Concentration (related to Major so put it near there)
		Minor
		IndustryOfInterest
		
		Change the address related columns to be prefixed by 
		"Current"
		
		Add a column for each address related column
		prefixed by "Permanent"
			--Long story short, she wants to have
			the user's current address and permanent
			address

		Gender
		
		HobbiesAndInterests
		MBTI
		
		(make this one varchar(512))
		Activities

(DONE)	Add the following columns to the Mentor table (make them varchar(200)
	because alot of these are going to allow for multiple selections
	from a list, so they could get really long)
		PreferredName
		GraduationYear
		Major
		Concentrations
		Minor
		ExtendedDegree
		CurrentIndustry
		OtherIndustryExpertise
		Gender
		HobbiesAndInterest
		MBTI
		
		(make this one varchar(512))
		Activities

		Change address columns to be prefixed by "Permanent"
